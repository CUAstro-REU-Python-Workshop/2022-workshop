{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Day 3 - Intro to Data Analysis using Pandas and Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [Pandas](https://pandas.pydata.org/) is a widely used and very powerful python library for data analysis. Pandas is efficient, since it is built on top of NumPy, but also adds a lot of convenience layers to make analysing data more straightforward than using raw NumPy. The library can deal with a lot of widely used file formats such as csv, json, hdf5, ..., and also databases such as SQL. Pandas also interoperates cleanly with existing python libraries such as NumPy, matplotlib, or machine learning libraries such as scikit-learn.\n",
    " \n",
    " [Seaborn](https://seaborn.pydata.org/) is a data visualization library which provides functionality to create plots that would be quite involved using pure matplotlib in only a few lines of python, and it understands Pandas dataframes by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, lets get some imports out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd \n",
    "import seaborn as sns # This is the usual way seaborn is abbreviated. Apparently it's an inside reference to The West Wing\n",
    "sns.set() # Use seaborn's settings to plot, which looks a lot nicer than the matplotlib default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much like how the NumPy library is built around the central object of the NumPy array, Pandas is built around the central objects of the Pandas Dataframe and the Pandas Series. A Dataframe holds 2-dimensional tabular data, such as the data in a .csv file, in a python object. A Series holds 1-dimensional data, and each column of a DataFrame is a Series. There are a number of ways to create a DataFrame from data in python. One way is to construct a DataFrame from a dictionary of lists, mapping the names of each column to a list of values. Here's some not-quite-true data from the last Irish election. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(\n",
    "    {'Political_Party': ['Sinn Fein', 'Fine Gael', 'Fianna Fail', 'Greens', 'Social Democrats'] ,\n",
    "     'Leader': ['Mary-Lou MacDonald', 'Leo Varadkar', 'Michael Martin', 'Eamon Ryan', 'Roisin Shortall'],\n",
    "     'MPs': [38, 34, 40, 12, 7], \n",
    "     'Vote share %': [40, 10, 20, 10, 5]\n",
    "   }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that by default jupyter formats DataFrames to be a bit more human readable than it does with NumPy arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the columns of a DataFrame as it were a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Political_Party'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the columns of the DataFrame as attributes using `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Political_Party)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that columns of DataFrame support tab completion which is really useful. Try pressing the tab key with the cursor at the end of `df.Pol` below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "\n",
    "A lot of the time, you would be interested in manipulating data that already exists. In this case we'd commonly read data from something like a .csv file. CSV stands for \"Comma-seperated values\" and is a common file format for representing columns of data, which are seperated by commas as the name implies. CSV files are human readable, and understood by Pandas, Excel and pretty much any data application. For this tutorial, we'll take advantage of the fact that seaborn has a few sample datasets which we can grab on demand without having to deal with the `.csv` file directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the Iris dataset. It is a collection of images of flowers and contains info on which species each flower is, and the width and length of its petals and sepals. This is a good dataset for us to look at since it combines numerical data (the sepal, petal widths) and categorical data (the species) which we use to demonstrate the power of pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that we have our data loaded in python, we can start to explore the data. We can print the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The method `describe` will give us a statistical summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `Count` just tells us how many times each field appears, which is 150 for each field here. Some datasets will have missing data, which are represented by 'NaN' (Not a Number) in which case `count` will not be the same for each field. The rest of the rows give a statistical summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The head method shows the first few rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DataFrames behave like dicts, and we can access each column by its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['species']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have categorical data and want to see only the unique values, there's a few things we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(iris['species']))\n",
    "\n",
    "# or \n",
    "print(set(iris['species']))\n",
    "\n",
    "# or, to also get the count\n",
    "from collections import Counter\n",
    "print(Counter(iris['species']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access multiple columns by passing a list of names. This will return a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[['species', 'sepal_width']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " We can also use the index to access the rows using the `loc` method. (Note that indexing with loc *includes* the endpoint of the range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[0:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can do much fancier indexing than just by the index value. As we saw when we called `.describe` above, the petal_width varied from 0.1 to 2.5. Let's say we're only interested in parts of the data where the sepal_width is less than 1.5. Pandas' powerful boolean indexing features let us index by a boolean. We assign the result to a new DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_small_flowers = iris[iris['petal_width'] < 1.5]\n",
    "iris_small_flowers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Math using the columns of dataframes is vectorized, in that math operations get applied to every entry in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_area = iris['petal_width'] * iris['petal_length']\n",
    "petal_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can also add data to a DataFrame. New columns by default get appended to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['petal_area'] = petal_area\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data\n",
    "\n",
    "One strength of pandas is that a DataFrame can easily be loaded to and from a lot of different types of data formats, .csv, .hdf5, excel files, SQL database, ... very straightforwardly using `to_*` and `from_*` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.to_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat iris.csv #Print out the contents of the file iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_iris = pd.read_csv(\"iris.csv\", index_col=0)\n",
    "new_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    " Add a new column to the iris data set representing the petal 'aspect_ratio', it's length divided by its width. \n",
    " \n",
    " Also, using the boolean index feature, produce a DataFrame which only has data for the virginica species. Call `.describe()` on the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Plotting.\n",
    " \n",
    " If we're trying to analyse data, we usually want to do a bit more than just see standard deviations and means. Pandas offers a thin wrapper around matplotlib to allow us to easily do simple plots to explore our data. Note that everything we do here can be done directly with matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Perhaps we expect their to be a correlation between sepal length and petal length, we can do a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot.scatter(x='petal_length', y='sepal_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also color the dots by the value in a different column by specifying `c=`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.plot.scatter('petal_length', 'sepal_length', c='sepal_width', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " One of the nice things about using the Pandas plotting interface is certain things, such as the axes being labeled by the column name is done automatically. \n",
    " \n",
    "We might also want to plot a histogram of a single column. We then call `plot` on the Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris['sepal_length'].plot.hist(bins=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, if we just call `.hist` directly Pandas will generate all of the histograms for whatever columns the data is numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: \n",
    "Let's explore some of the other plotting functionality in pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in dir(iris.plot) if not i.startswith('_')]    # list of functions/methods in iris.plot that don't start with '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try plotting iris using box plot. This plot shows the min, max, mean, 25, 50, and 75 quartiles along with outliers in a single plot. More on box plots [here](https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a scatter plot of 'petal_width' and 'petal_length', but instead of coloring each point based on the 'sepal_width', change the size of the point based on the value of 'sepal_width' using the `s=` option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    " If you look at our initial scatter plot, you might start to think we're not \n",
    " analysing our data as we should. Notice that there is a cluster of values in the bottom \n",
    " left. This is because our data is categorical; one should expect that the different species\n",
    " have different characteristic petal and sepal sizes, and we'd like our plots to show that \n",
    " distinction. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas let's us easily group data using the `groupby` method. So let's go ahead and group our data by species so we can more usefully analyse it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = iris.groupby('species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a `GroupBy` object which we must do some operation on to get useful data. We can get statistics easily: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we're now getting means and standard deviations within each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to we could iterate over `g` to get the three DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for species, subdf in g: \n",
    "    plt.scatter(subdf['sepal_length'], subdf['petal_length'], label=species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're starting to see that the clustering is indeed due to the seperate species. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted the scatter plots to be seperate, we could have just called plot on the `GroupBy` object `g` itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.plot.scatter('sepal_length', 'petal_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will work for any type of plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.boxplot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We see that the data is much less spread out when we account for the different species. \n",
    "\n",
    "As you can see, `.groupby` is quite powerful when we want to split our data into different categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn functionality. \n",
    "\n",
    "Let's finally just look at some seaborn functionality to make our plots even nicer. Seaborn uses slightly different names for the plotting functions but we can do things much more easily with it. \n",
    "\n",
    "Seaborn's plot is called `.relplot` which stands for 'relationship plot' and a few more options we can avail of to produce a more useful plot with one function call. By default it uses a scatter plot, but we could switch to line plot with `kind='line'` if it was appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='petal_length', y='sepal_length', hue='species', data=iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acheived the colouring which we have to use `groupby` with a for loop to get in one call thanks to the `hue` option!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily find and plot a line of best fit using `lmplot`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='petal_length', y='sepal_length', data=iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.distplot` will plot a histogram. It will also plot a 'kernel destiny estimator' which is a smoothed approximation to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(iris.petal_length, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn has easy functions to combine scatter plots and histograms onto one figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='petal_length', y='sepal_length', data=iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even get this info for the whole dataset in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=iris, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a cursory overview of what seaborn and pandas can do. Hopefully I've convinced you that if you have data, then pandas and seaborn can save you a lot of trouble in analysing it and plotting it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task \n",
    "\n",
    "We've looked at the iris dataset, but lets look at a different dataset and do some exploratory analysis on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.get_dataset_names() # this is all of the available datasets in seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planets is a dataset of exoplanets we found, perfect for us! Do some exploration of the dataset, printing, using `.describe()`, `.head()` etc. Which columns are categorical? Which are numeric? Is there any missing data (represented by NaN)?\n",
    "\n",
    "Some things you might interested in observing: \n",
    "- Plot a histogram of the year of discovery to see how many more planets we find now. \n",
    "- Try a box plot comparing the distance and method. \n",
    "- Try an sns.pairplot (You may need 'dropna=True' for it to handle the NaN's)\n",
    "- Try to group the data by 'method' and call count. Which method has found the most planets? Which methods do or do not provide mass estimate? \n",
    "\n",
    "The goal of pandas and seaborn is to explore, so try different things yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
